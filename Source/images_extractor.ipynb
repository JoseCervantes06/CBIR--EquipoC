{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52e7f887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "from PIL import Image, UnidentifiedImageError, ImageFilter\n",
    "\n",
    "def read_images_categories(image_dir, num_imgs_per_categorie):\n",
    "    directories = [\"drawings\", \"engraving\", \"iconography\", \"painting\", \"sculpture\"]\n",
    "    categories = []\n",
    "    images = []\n",
    "    filenames = []\n",
    "    \n",
    "    seen_hashes = set() \n",
    "    print(f\"Iniciando carga y preprocesamiento desde: {image_dir}\")\n",
    "\n",
    "    for directory in directories:\n",
    "        path = os.path.join(image_dir, directory)\n",
    "        \n",
    "        if not os.path.isdir(path):\n",
    "            print(f\"Advertencia: La carpeta {path} no existe. Saltando.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Procesando clase: {directory}...\")\n",
    "        count = 0\n",
    "        \n",
    "        files = os.listdir(path)\n",
    "        \n",
    "        for img_name in files:\n",
    "            if count >= num_imgs_per_categorie:\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                img_path = os.path.join(path, img_name)\n",
    "                \n",
    "                img = Image.open(img_path)\n",
    "                \n",
    "                img = img.convert('RGB')\n",
    "                \n",
    "                img_hash = hashlib.md5(img.tobytes()).hexdigest()\n",
    "                if img_hash in seen_hashes:\n",
    "                    # print(f\" -> Duplicado detectado e ignorado: {img_name}\")\n",
    "                    continue \n",
    "                seen_hashes.add(img_hash)\n",
    "\n",
    "                img = img.filter(ImageFilter.SMOOTH) \n",
    "                \n",
    "                images.append(img)\n",
    "                categories.append(directory)\n",
    "                filenames.append(img_name)\n",
    "                count += 1\n",
    "\n",
    "            except (UnidentifiedImageError, OSError):\n",
    "                # print(f\" -> Error leyendo o procesando: {img_name}\")\n",
    "                continue\n",
    "\n",
    "    print(f\"Proceso finalizado. Total imágenes limpias: {len(images)} | Total etiquetas: {len(categories)}\")\n",
    "    \n",
    "    return images, categories, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d788a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando carga y preprocesamiento desde: ../data/dataset/training_set\n",
      "Procesando clase: drawings...\n",
      "Procesando clase: engraving...\n",
      "Procesando clase: iconography...\n",
      "Procesando clase: painting...\n",
      "Procesando clase: sculpture...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OMEN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso finalizado. Total imágenes limpias: 2000 | Total etiquetas: 2000\n",
      "\n",
      "--- Resultado ---\n",
      "Total imágenes cargadas: 2000\n",
      "Dimensiones de la primera imagen: (644, 475)\n",
      "Etiqueta de la primera imagen: drawings\n",
      "Etiqueta de la última imagen: sculpture\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "ruta_dataset = \"../data/dataset/training_set\" \n",
    "\n",
    "cantidad_por_clase = 400\n",
    "\n",
    "mis_imagenes, mis_etiquetas, mis_rutas = read_images_categories(ruta_dataset, cantidad_por_clase)\n",
    "\n",
    "if len(mis_imagenes) > 0:\n",
    "    print(\"\\n--- Resultado ---\")\n",
    "    print(f\"Total imágenes cargadas: {len(mis_imagenes)}\")\n",
    "    print(f\"Dimensiones de la primera imagen: {mis_imagenes[0].size}\")\n",
    "    print(f\"Etiqueta de la primera imagen: {mis_etiquetas[0]}\")\n",
    "    print(f\"Etiqueta de la última imagen: {mis_etiquetas[-1]}\")\n",
    "else:\n",
    "    print(\"No se cargaron imágenes. Revisa que la 'ruta_dataset' sea correcta.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f724877f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n",
      "Preprocesando imágenes (se hace una sola vez)...\n",
      "Tensor de entrada completo: torch.Size([2000, 3, 224, 224])\n",
      "\n",
      "================================================\n",
      " INICIANDO PROCESO PARA: VGG16\n",
      "================================================\n",
      "Extrayendo características con VGG16...\n",
      "  -> Procesado lote 0 a 32\n",
      "  -> Procesado lote 160 a 192\n",
      "  -> Procesado lote 320 a 352\n",
      "  -> Procesado lote 480 a 512\n",
      "  -> Procesado lote 640 a 672\n",
      "  -> Procesado lote 800 a 832\n",
      "  -> Procesado lote 960 a 992\n",
      "  -> Procesado lote 1120 a 1152\n",
      "  -> Procesado lote 1280 a 1312\n",
      "  -> Procesado lote 1440 a 1472\n",
      "  -> Procesado lote 1600 a 1632\n",
      "  -> Procesado lote 1760 a 1792\n",
      "  -> Procesado lote 1920 a 1952\n",
      "Extracción completada. Forma final: (2000, 25088)\n",
      "Entrenando índice FAISS (dim=25088)...\n",
      "Índice guardado exitosamente en: ../Data/feature/VGG16.index\n",
      "Memoria liberada. Listo para el siguiente modelo.\n",
      "\n",
      "================================================\n",
      " INICIANDO PROCESO PARA: ResNet50\n",
      "================================================\n",
      "Extrayendo características con ResNet50...\n",
      "  -> Procesado lote 0 a 32\n",
      "  -> Procesado lote 160 a 192\n",
      "  -> Procesado lote 320 a 352\n",
      "  -> Procesado lote 480 a 512\n",
      "  -> Procesado lote 640 a 672\n",
      "  -> Procesado lote 800 a 832\n",
      "  -> Procesado lote 960 a 992\n",
      "  -> Procesado lote 1120 a 1152\n",
      "  -> Procesado lote 1280 a 1312\n",
      "  -> Procesado lote 1440 a 1472\n",
      "  -> Procesado lote 1600 a 1632\n",
      "  -> Procesado lote 1760 a 1792\n",
      "  -> Procesado lote 1920 a 1952\n",
      "Extracción completada. Forma final: (2000, 2048)\n",
      "Entrenando índice FAISS (dim=2048)...\n",
      "Índice guardado exitosamente en: ../Data/feature/ResNet50.index\n",
      "Memoria liberada. Listo para el siguiente modelo.\n",
      "\n",
      "================================================\n",
      " INICIANDO PROCESO PARA: InceptionV3\n",
      "================================================\n",
      "Extrayendo características con InceptionV3...\n",
      "  -> Procesado lote 0 a 32\n",
      "  -> Procesado lote 160 a 192\n",
      "  -> Procesado lote 320 a 352\n",
      "  -> Procesado lote 480 a 512\n",
      "  -> Procesado lote 640 a 672\n",
      "  -> Procesado lote 800 a 832\n",
      "  -> Procesado lote 960 a 992\n",
      "  -> Procesado lote 1120 a 1152\n",
      "  -> Procesado lote 1280 a 1312\n",
      "  -> Procesado lote 1440 a 1472\n",
      "  -> Procesado lote 1600 a 1632\n",
      "  -> Procesado lote 1760 a 1792\n",
      "  -> Procesado lote 1920 a 1952\n",
      "Extracción completada. Forma final: (2000, 2048)\n",
      "Entrenando índice FAISS (dim=2048)...\n",
      "Índice guardado exitosamente en: ../Data/feature/InceptionV3.index\n",
      "Memoria liberada. Listo para el siguiente modelo.\n",
      "\n",
      "================================================\n",
      " INICIANDO PROCESO PARA: ColorHistogram\n",
      "================================================\n",
      "Extrayendo características con ColorHistogram...\n",
      "  -> Procesado lote 0 a 32\n",
      "  -> Procesado lote 160 a 192\n",
      "  -> Procesado lote 320 a 352\n",
      "  -> Procesado lote 480 a 512\n",
      "  -> Procesado lote 640 a 672\n",
      "  -> Procesado lote 800 a 832\n",
      "  -> Procesado lote 960 a 992\n",
      "  -> Procesado lote 1120 a 1152\n",
      "  -> Procesado lote 1280 a 1312\n",
      "  -> Procesado lote 1440 a 1472\n",
      "  -> Procesado lote 1600 a 1632\n",
      "  -> Procesado lote 1760 a 1792\n",
      "  -> Procesado lote 1920 a 1952\n",
      "Extracción completada. Forma final: (2000, 192)\n",
      "Entrenando índice FAISS (dim=192)...\n",
      "Índice guardado exitosamente en: ../Data/feature/ColorHistogram.index\n",
      "Memoria liberada. Listo para el siguiente modelo.\n",
      "\n",
      "================================================\n",
      " INICIANDO PROCESO PARA: LBP\n",
      "================================================\n",
      "Extrayendo características con LBP...\n",
      "  -> Procesado lote 0 a 32\n",
      "  -> Procesado lote 160 a 192\n",
      "  -> Procesado lote 320 a 352\n",
      "  -> Procesado lote 480 a 512\n",
      "  -> Procesado lote 640 a 672\n",
      "  -> Procesado lote 800 a 832\n",
      "  -> Procesado lote 960 a 992\n",
      "  -> Procesado lote 1120 a 1152\n",
      "  -> Procesado lote 1280 a 1312\n",
      "  -> Procesado lote 1440 a 1472\n",
      "  -> Procesado lote 1600 a 1632\n",
      "  -> Procesado lote 1760 a 1792\n",
      "  -> Procesado lote 1920 a 1952\n",
      "Extracción completada. Forma final: (2000, 26)\n",
      "Entrenando índice FAISS (dim=26)...\n",
      "Índice guardado exitosamente en: ../Data/feature/LBP.index\n",
      "Memoria liberada. Listo para el siguiente modelo.\n",
      "\n",
      "------------------------------------------------\n",
      "Proceso completado para todos los modelos.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import faiss\n",
    "import gc  # Garbage Collector para liberar memoria entre modelos, al inicio era lento o se quedaba sin memoria\n",
    "from torchvision import transforms\n",
    "from feature_extractor import MyVGG16, MyResNet50, MyInceptionV3, MyColorHistogram, MyLBP\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Lista de modelos a ejecutar: (Nombre_Archivo, Clase)\n",
    "modelos_ = [\n",
    "    (\"VGG16\", MyVGG16),\n",
    "    (\"ResNet50\", MyResNet50),\n",
    "    (\"InceptionV3\", MyInceptionV3), \n",
    "    (\"ColorHistogram\", MyColorHistogram),\n",
    "    (\"LBP\", MyLBP)\n",
    "]\n",
    "\n",
    "# Preprocesamiento \n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "print(\"Preprocesando imágenes (se hace una sola vez)...\")\n",
    "input_batch = torch.stack([preprocess(img) for img in mis_imagenes])\n",
    "print(f\"Tensor de entrada completo: {input_batch.shape}\")\n",
    "\n",
    "num_images = input_batch.shape[0]\n",
    "batch_size = 32 # No saturar la memoria \n",
    "\n",
    "for nombre_modelo, ClaseModelo in modelos_:\n",
    "    print(f\"\\n================================================\")\n",
    "    print(f\" INICIANDO PROCESO PARA: {nombre_modelo}\")\n",
    "    print(f\"================================================\")\n",
    "\n",
    "    extractor = ClaseModelo(device=device)\n",
    "    \n",
    "    all_features_list = []\n",
    "\n",
    "    # Extracción por lotes\n",
    "    print(f\"Extrayendo características con {nombre_modelo}...\")\n",
    "    for i in range(0, num_images, batch_size):\n",
    "        batch = input_batch[i : i + batch_size]\n",
    "        \n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        features = extractor.extract_features(batch)\n",
    "        all_features_list.append(features)\n",
    "        \n",
    "        if i % (batch_size * 5) == 0:\n",
    "            print(f\"  -> Procesado lote {i} a {min(i + batch_size, num_images)}\")\n",
    "\n",
    "    # Concatenar resultados\n",
    "    final_features = np.vstack(all_features_list)\n",
    "    print(f\"Extracción completada. Forma final: {final_features.shape}\")\n",
    "\n",
    "    # 4. Crear y Guardar índice FAISS\n",
    "    features_db = final_features.astype('float32')\n",
    "    d = features_db.shape[1] # Dimensión de los vectores \n",
    "    index = faiss.IndexFlatL2(d)\n",
    "    print(f\"Entrenando índice FAISS (dim={d})...\")\n",
    "    index.add(features_db)\n",
    "    \n",
    "    output_path = f\"../Data/feature/{nombre_modelo}.index\"\n",
    "    faiss.write_index(index, output_path)\n",
    "    print(f\"Índice guardado exitosamente en: {output_path}\")\n",
    "\n",
    "    # Limpieza de memoria\n",
    "    del extractor\n",
    "    del final_features\n",
    "    del features_db\n",
    "    del index\n",
    "    torch.cuda.empty_cache() # Libera caché \n",
    "    gc.collect() # Garbage collector de Python, teniamos problemas de memoria\n",
    "    print(f\"Memoria liberada. Listo para el siguiente modelo.\")\n",
    "\n",
    "print(\"\\n------------------------------------------------\")\n",
    "print(\"Proceso completado para todos los modelos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d2b8b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadatos guardados como 'image_metadata.json'\n"
     ]
    }
   ],
   "source": [
    "metadata = []\n",
    "\n",
    "for filename, category in zip(mis_rutas, mis_etiquetas):\n",
    "    metadata.append({\n",
    "        \"filename\": filename,\n",
    "        \"category\": category,\n",
    "        \"path\": f\"Data/dataset/training_set/{category}/{filename}\" \n",
    "    })\n",
    "\n",
    "with open('../Data/image_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "\n",
    "print(\"Metadatos guardados como 'image_metadata.json'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
