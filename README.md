# CBIR--EquipoC

## IntroducciÃ³n

Este proyecto aborda el problema de la **RecuperaciÃ³n de ImÃ¡genes Basada en Contenido (CBIR)**. El sistema utiliza algoritmos de indexaciÃ³n y bÃºsqueda eficiente mediante la librerÃ­a **FAISS** (Facebook AI Similarity Search).

El objetivo es combinar y evaluar simultÃ¡neamente mÃºltiples mÃ©todos de extracciÃ³n de caracterÃ­sticas para comparar su precisiÃ³n y rendimiento

![Diagrama de arquitectura del sistema CBIR](Arquitectura_CBIR.png)

## ðŸ› ï¸ Entorno de ejecuciÃ³n 

Para clonar, instalar y ejecutar este proyecto correctamente, necesitarÃ¡s las siguientes herramientas y dependencias:

### 1. Requisitos de Software

AsegÃºrate de tener instalados:

* **Python:** VersiÃ³n 3.11
* **Gestor de paquetes:** `pip` (recomendado) o `conda`.
* **Git:** Para clonar el repositorio.

### 2. Instalar Dependencias de Python

Todas las librerÃ­as necesarias se encuentran especificadas en el archivo `requirements.txt`. Ejecuta el siguiente comando en la terminal (funciona en **Windows, macOS y Linux**):

```bash
pip install -r requirements.txt
```
## ðŸ“ PreparaciÃ³n del Dataset

Para ejecutar el proyecto, es necesario descargar las imÃ¡genes y organizarlas correctamente en la estructura de carpetas.

### 1. Descarga y ConfiguraciÃ³n

I.  **Descargar:** Descarga el archivo `.zip` del dataset "Art Images" desde Kaggle haciendo clic en el siguiente enlace:
    * [ðŸ”— Kaggle - Art Images](https://www.kaggle.com/datasets/thedownhill/art-images-drawings-painting-sculpture-engraving)

II.  **Descomprimir:** Extrae el contenido del archivo `.zip`.

III.  **Organizar:** Mueve la carpeta descomprimida llamada `dataset` dentro de la carpeta `Data` de este proyecto.

### 2. Estructura del Proyecto

Para que el proyecto funcione sin errores, asegÃºrate de que tu directorio de trabajo tenga exactamente la siguiente estructura:

```text
CBIR--EquipoC/
â”‚
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ Feature/       # Carpeta para caracterÃ­sticas extraÃ­das
â”‚   â””â”€â”€ dataset/       # Carpeta con las imÃ¡genes 
â”‚
â”œâ”€â”€ source/
â”‚   â”œâ”€â”€ feature_extractor.py   
â”‚   â”œâ”€â”€ images_extractor.ipynb    
â”‚
â”œâ”€â”€ main.py            # Archivo principal de ejecuciÃ³n
â””â”€â”€ requirements.txt
```

## ðŸš€ EjecuciÃ³n del Proyecto

### 1. ExtracciÃ³n de CaracterÃ­sticas e Indexado

Antes de poder buscar imÃ¡genes, el sistema necesita "aprender" y catalogar el dataset.

1.  Abre y ejecuta todas las celdas del notebook **`./Source/images_extractor.ipynb`**.
2.  Este script procesarÃ¡ las imÃ¡genes y guardarÃ¡ los Ã­ndices vectoriales de FAISS en el directorio `./Data/Feature/`.

El sistema generarÃ¡ Ã­ndices independientes para cada uno de los siguientes modelos:
* VGG16, ResNet50, InceptionV3, Histograma RGB y LBP (Local Binary Patterns).

> **Nota:** Dependiendo de tu hardware (CPU vs GPU) y del tamaÃ±o del dataset, este proceso puede tardar varios minutos.

### 2. Iniciar la Interfaz de Usuario

Una vez que los archivos de caracterÃ­sticas se han generado, puedes iniciar la aplicaciÃ³n web. Ejecuta el siguiente comando en tu terminal (asegurÃ¡ndote de estar en la carpeta raÃ­z del proyecto):

```bash
streamlit run main.py
```

> **Nota:** Se puedes modificar algunos parametros de images_extractor (batch, cantidad_por_clase)
